2022-09-07 02:23:06,603:main_ZINC_graph_regression.py:443 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 25, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12}
2022-09-07 02:23:06,604:main_ZINC_graph_regression.py:444 -                 main(): {'L': 16, 'hidden_dim': 59, 'out_dim': 59, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc_dim': 6, 'pe_init': 'gape', 'use_lapeig_loss': True, 'alpha_loss': 1, 'lambda_loss': 0.1, 'gpu_id': 0, 'batch_size': 128, 'n_gape': 1, 'gape_pooling': 'mean', 'matrix_type': 'RWK', 'device': device(type='cuda'), 'log_file': '/afs/crc.nd.edu/user/p/psoga/gnn-lspe/tests/ZINC/GatedGCN/gape/lspe-eigloss-ngape1-rwk/6_DEBUG.log', 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-07 02:23:07,888:main_ZINC_graph_regression.py:467 -                 main(): Total number of parameters: 520833
2022-09-07 02:23:07,920:main_ZINC_graph_regression.py:135 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (6).
2022-09-07 02:24:12,445:main_ZINC_graph_regression.py:141 -   train_val_pipeline(): Time PE:64.55591583251953
2022-09-07 02:24:12,450:main_ZINC_graph_regression.py:171 -   train_val_pipeline(): Training Graphs: 10000
2022-09-07 02:24:12,451:main_ZINC_graph_regression.py:172 -   train_val_pipeline(): Validation Graphs: 10000
2022-09-07 02:24:12,451:main_ZINC_graph_regression.py:173 -   train_val_pipeline(): Test Graphs: 10000
2022-09-07 02:24:34,942:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [0] Train Loss: 1177.6096 | Train MAE: 1177.6090 | Val Loss: 897.5205 | Val MAE: 897.5198 | Test MAE: 897.0795 | Time: 22.4866
2022-09-07 02:24:57,377:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [1] Train Loss: 667.5730 | Train MAE: 667.5724 | Val Loss: 486.9888 | Val MAE: 486.9882 | Test MAE: 486.6677 | Time: 22.3850
2022-09-07 02:25:23,902:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [2] Train Loss: 500.8027 | Train MAE: 500.8021 | Val Loss: 1196.6151 | Val MAE: 1196.6144 | Test MAE: 1196.3504 | Time: 26.4764
2022-09-07 02:25:46,588:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [3] Train Loss: 451.9158 | Train MAE: 451.9152 | Val Loss: 187.0198 | Val MAE: 187.0192 | Test MAE: 187.0481 | Time: 22.6348
2022-09-07 02:26:08,940:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [4] Train Loss: 173.0428 | Train MAE: 173.0421 | Val Loss: 118.2648 | Val MAE: 118.2641 | Test MAE: 118.3017 | Time: 22.3003
2022-09-07 02:26:31,401:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [5] Train Loss: 113.3563 | Train MAE: 113.3556 | Val Loss: 118.7027 | Val MAE: 118.7020 | Test MAE: 118.6637 | Time: 22.4126
2022-09-07 02:26:54,092:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [6] Train Loss: 99.3727 | Train MAE: 99.3721 | Val Loss: 127.1822 | Val MAE: 127.1816 | Test MAE: 127.2060 | Time: 22.6401
