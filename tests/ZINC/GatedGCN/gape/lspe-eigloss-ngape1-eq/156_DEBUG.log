2022-08-31 23:19:32,151:main_ZINC_graph_regression.py:443 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 25, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12}
2022-08-31 23:19:32,152:main_ZINC_graph_regression.py:444 -                 main(): {'L': 16, 'hidden_dim': 59, 'out_dim': 59, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc_dim': 156, 'pe_init': 'gape', 'use_lapeig_loss': True, 'alpha_loss': 1, 'lambda_loss': 0.1, 'gpu_id': 0, 'batch_size': 128, 'n_gape': 1, 'device': device(type='cuda'), 'log_file': '/afs/crc.nd.edu/user/p/psoga/gnn-lspe/tests/ZINC/GatedGCN/gape/lspe-eigloss-ngape1-eq/156_DEBUG.log', 'num_atom_type': 28, 'num_bond_type': 4}
2022-08-31 23:19:33,615:main_ZINC_graph_regression.py:467 -                 main(): Total number of parameters: 580833
2022-08-31 23:19:33,650:main_ZINC_graph_regression.py:135 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (156).
2022-08-31 23:23:08,856:main_ZINC_graph_regression.py:141 -   train_val_pipeline(): Time PE:215.2405092716217
2022-08-31 23:23:08,863:main_ZINC_graph_regression.py:171 -   train_val_pipeline(): Training Graphs: 10000
2022-08-31 23:23:08,863:main_ZINC_graph_regression.py:172 -   train_val_pipeline(): Validation Graphs: 10000
2022-08-31 23:23:08,863:main_ZINC_graph_regression.py:173 -   train_val_pipeline(): Test Graphs: 10000
2022-08-31 23:23:57,240:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [0] Train Loss: 1.5850 | Train MAE: 1.5797 | Val Loss: 1.4585 | Val MAE: 1.4541 | Test MAE: 1.6063 | Time: 48.3724
2022-08-31 23:24:45,626:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [1] Train Loss: 1.5053 | Train MAE: 1.4998 | Val Loss: 1.4897 | Val MAE: 1.4847 | Test MAE: 1.5965 | Time: 48.3187
2022-08-31 23:25:33,233:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [2] Train Loss: 1.4990 | Train MAE: 1.4934 | Val Loss: 1.4579 | Val MAE: 1.4530 | Test MAE: 1.5936 | Time: 47.5538
2022-08-31 23:26:21,110:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [3] Train Loss: 1.4933 | Train MAE: 1.4877 | Val Loss: 1.4497 | Val MAE: 1.4446 | Test MAE: 1.5917 | Time: 47.8211
2022-08-31 23:27:09,787:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [4] Train Loss: 1.4858 | Train MAE: 1.4803 | Val Loss: 1.4355 | Val MAE: 1.4315 | Test MAE: 1.5690 | Time: 48.6219
2022-08-31 23:27:57,897:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [5] Train Loss: 1.4835 | Train MAE: 1.4780 | Val Loss: 1.4542 | Val MAE: 1.4491 | Test MAE: 1.6290 | Time: 48.0539
2022-08-31 23:28:45,754:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [6] Train Loss: 1.5002 | Train MAE: 1.4947 | Val Loss: 1.4137 | Val MAE: 1.4085 | Test MAE: 1.5281 | Time: 47.7985
2022-08-31 23:29:33,677:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [7] Train Loss: 1.4542 | Train MAE: 1.4492 | Val Loss: 1.3855 | Val MAE: 1.3810 | Test MAE: 1.5388 | Time: 47.8702
2022-08-31 23:30:21,600:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [8] Train Loss: 1.4385 | Train MAE: 1.4340 | Val Loss: 1.3486 | Val MAE: 1.3454 | Test MAE: 1.8297 | Time: 47.8634
2022-08-31 23:31:09,399:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [9] Train Loss: 1.3565 | Train MAE: 1.3519 | Val Loss: 1.1975 | Val MAE: 1.1923 | Test MAE: 2.9187 | Time: 47.7270
2022-08-31 23:31:57,678:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [10] Train Loss: 1.4536 | Train MAE: 1.4482 | Val Loss: 1.1561 | Val MAE: 1.1510 | Test MAE: 2.4020 | Time: 48.2237
2022-08-31 23:32:45,606:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [11] Train Loss: 1.2409 | Train MAE: 1.2354 | Val Loss: 1.1228 | Val MAE: 1.1177 | Test MAE: 1.8492 | Time: 47.8743
2022-08-31 23:33:33,923:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [12] Train Loss: 1.2425 | Train MAE: 1.2371 | Val Loss: 1.0520 | Val MAE: 1.0468 | Test MAE: 1.5734 | Time: 48.2641
2022-08-31 23:34:22,368:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [13] Train Loss: 1.1375 | Train MAE: 1.1320 | Val Loss: 0.9825 | Val MAE: 0.9774 | Test MAE: 1.5634 | Time: 48.3845
2022-08-31 23:35:11,087:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [14] Train Loss: 1.0260 | Train MAE: 1.0205 | Val Loss: 0.9027 | Val MAE: 0.8975 | Test MAE: 0.9969 | Time: 48.6672
2022-08-31 23:35:58,683:main_ZINC_graph_regression.py:216 -   train_val_pipeline(): Epoch [15] Train Loss: 1.3706 | Train MAE: 1.3651 | Val Loss: 1.0335 | Val MAE: 1.0282 | Test MAE: 13.6028 | Time: 47.5386
